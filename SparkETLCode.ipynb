{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "os.environ[\"PYSPARK_PYTHON\"] = \"/opt/cloudera/parcels/Anaconda/bin/python\"\n",
    "os.environ[\"JAVA_HOME\"] = \"/usr/java/jdk1.8.0_232-cloudera/jre\"\n",
    "os.environ[\"SPARK_HOME\"]=\"/opt/cloudera/parcels/SPARK2-2.3.0.cloudera2-1.cdh5.13.3.p0.316101/lib/spark2/\"\n",
    "os.environ[\"PYLIB\"] = os.environ[\"SPARK_HOME\"] + \"/python/lib\"\n",
    "sys.path.insert(0, os.environ[\"PYLIB\"] +\"/py4j-0.10.6-src.zip\")\n",
    "sys.path.insert(0, os.environ[\"PYLIB\"] +\"/pyspark.zip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://ip-10-0-0-45.ec2.internal:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v2.3.0.cloudera2</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>yarn-client</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>jupyter_Spark</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        "
      ],
      "text/plain": [
       "<SparkContext master=yarn-client appName=jupyter_Spark>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark import SparkContext, SparkConf\n",
    "conf = SparkConf().setAppName(\"jupyter_Spark\").setMaster(\"yarn-client\")\n",
    "sc = SparkContext(conf=conf)\n",
    "sc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - hive</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://ip-10-0-0-45.ec2.internal:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v2.3.0.cloudera2</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>yarn-client</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>jupyter_Spark</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7f90a133c210>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder.appName('demo').master(\"local\").enableHiveSupport().getOrCreate()\n",
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import StructType, StructField, IntegerType, StringType, BooleanType, DoubleType, LongType\n",
    "\n",
    "from pyspark.sql.functions import *\n",
    "\n",
    "from pyspark.sql.window import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a customized schema to avoid errors. \n",
    "#used strutfield funcion to create the col, type, isnull\n",
    "\n",
    "revisedSchema = StructType([StructField('year', IntegerType(),True),                            \n",
    "                            StructField('month', StringType(),True),\n",
    "                            StructField('day', IntegerType(),True),\n",
    "                            StructField('weekday', StringType(),True),\n",
    "                            StructField('hour', IntegerType(),True),\n",
    "                            StructField('atm_status', StringType(),True),\n",
    "                            StructField('atm_id', StringType(),True),\n",
    "                            StructField('atm_manufacturer', StringType(),True),\n",
    "                            StructField('atm_location', StringType(),True),\n",
    "                            StructField('atm_streetname', StringType(),True),\n",
    "                            StructField('atm_street_number', IntegerType(),True),\n",
    "                            StructField('atm_zipcode', IntegerType(),True),\n",
    "                            StructField('atm_lat', DoubleType(),True),\n",
    "                            StructField('atm_lon', DoubleType(),True),\n",
    "                            StructField('currency', StringType(),True),\n",
    "                            StructField('card_type', StringType(),True),\n",
    "                            StructField('transaction_amount', IntegerType(),True),\n",
    "                            StructField('service', StringType(),True),\n",
    "                            StructField('message_code', StringType(),True),\n",
    "                            StructField('message_text', StringType(),True),\n",
    "                            StructField('weather_lat', DoubleType(),True),\n",
    "                            StructField('weather_lon', DoubleType(),True),\n",
    "                            StructField('weather_city_id', LongType(),True),\n",
    "                            StructField('weather_city_name', StringType(),True),\n",
    "                            StructField('temp', DoubleType(),True),\n",
    "                            StructField('pressure', IntegerType(),True),\n",
    "                            StructField('humidity', IntegerType(),True),\n",
    "                            StructField('wind_speed', IntegerType(),True),\n",
    "                            StructField('wind_deg', IntegerType(),True),\n",
    "                            StructField('rain_3h', DoubleType(),True),\n",
    "                            StructField('clouds_all', IntegerType(),True),\n",
    "                            StructField('weather_id', IntegerType(),True),\n",
    "                            StructField('weather_main', StringType(),True),\n",
    "                            StructField('weather_description', StringType(),True)                            \n",
    "                           ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LOADING DATA FROM HDFS INTO DATAFRAME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- year: integer (nullable = true)\n",
      " |-- month: string (nullable = true)\n",
      " |-- day: integer (nullable = true)\n",
      " |-- weekday: string (nullable = true)\n",
      " |-- hour: integer (nullable = true)\n",
      " |-- atm_status: string (nullable = true)\n",
      " |-- atm_id: string (nullable = true)\n",
      " |-- atm_manufacturer: string (nullable = true)\n",
      " |-- atm_location: string (nullable = true)\n",
      " |-- atm_streetname: string (nullable = true)\n",
      " |-- atm_street_number: integer (nullable = true)\n",
      " |-- atm_zipcode: integer (nullable = true)\n",
      " |-- atm_lat: double (nullable = true)\n",
      " |-- atm_lon: double (nullable = true)\n",
      " |-- currency: string (nullable = true)\n",
      " |-- card_type: string (nullable = true)\n",
      " |-- transaction_amount: integer (nullable = true)\n",
      " |-- service: string (nullable = true)\n",
      " |-- message_code: string (nullable = true)\n",
      " |-- message_text: string (nullable = true)\n",
      " |-- weather_lat: double (nullable = true)\n",
      " |-- weather_lon: double (nullable = true)\n",
      " |-- weather_city_id: long (nullable = true)\n",
      " |-- weather_city_name: string (nullable = true)\n",
      " |-- temp: double (nullable = true)\n",
      " |-- pressure: integer (nullable = true)\n",
      " |-- humidity: integer (nullable = true)\n",
      " |-- wind_speed: integer (nullable = true)\n",
      " |-- wind_deg: integer (nullable = true)\n",
      " |-- rain_3h: double (nullable = true)\n",
      " |-- clouds_all: integer (nullable = true)\n",
      " |-- weather_id: integer (nullable = true)\n",
      " |-- weather_main: string (nullable = true)\n",
      " |-- weather_description: string (nullable = true)\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2468572"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Loading data from the HDFS path into the data frame\n",
    "#Using custom Schema\n",
    "df = spark.read.load(\"/user/root/ETL_Proj_Data/part-m-00000.snappy\", format=\"csv\", schema = revisedSchema)\n",
    "\n",
    "#printing the schema \n",
    "df.printSchema()\n",
    "\n",
    "#Check count after importing data into a dataframe\n",
    "df.select(\"*\").count()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-------+---+-------+----+----------+------+----------------+------------+-------------------+-----------------+-----------+-------+-------+--------+----------+------------------+----------+------------+------------+-----------+-----------+---------------+-----------------+------+--------+--------+----------+--------+-------+----------+----------+------------+--------------------+\n",
      "|year|  month|day|weekday|hour|atm_status|atm_id|atm_manufacturer|atm_location|     atm_streetname|atm_street_number|atm_zipcode|atm_lat|atm_lon|currency| card_type|transaction_amount|   service|message_code|message_text|weather_lat|weather_lon|weather_city_id|weather_city_name|  temp|pressure|humidity|wind_speed|wind_deg|rain_3h|clouds_all|weather_id|weather_main| weather_description|\n",
      "+----+-------+---+-------+----+----------+------+----------------+------------+-------------------+-----------------+-----------+-------+-------+--------+----------+------------------+----------+------------+------------+-----------+-----------+---------------+-----------------+------+--------+--------+----------+--------+-------+----------+----------+------------+--------------------+\n",
      "|2017|January|  1| Sunday|   0|    Active|     1|             NCR|  NÃƒÂ¦stved|        Farimagsvej|                8|       4700| 55.233| 11.763|     DKK|MasterCard|              5643|Withdrawal|        null|        null|      55.23|     11.761|        2616038|         Naestved|281.15|    1014|      87|         7|     260|  0.215|        92|       500|        Rain|          light rain|\n",
      "|2017|January|  1| Sunday|   0|  Inactive|     2|             NCR|    Vejgaard|         Hadsundvej|               20|       9000| 57.043|   9.95|     DKK|MasterCard|              1764|Withdrawal|        null|        null|     57.048|      9.935|        2616235|   NÃƒÂ¸rresundby|280.64|    1020|      93|         9|     250|   0.59|        92|       500|        Rain|          light rain|\n",
      "|2017|January|  1| Sunday|   0|  Inactive|     2|             NCR|    Vejgaard|         Hadsundvej|               20|       9000| 57.043|   9.95|     DKK|      VISA|              1891|Withdrawal|        null|        null|     57.048|      9.935|        2616235|   NÃƒÂ¸rresundby|280.64|    1020|      93|         9|     250|   0.59|        92|       500|        Rain|          light rain|\n",
      "|2017|January|  1| Sunday|   0|  Inactive|     3|             NCR|       Ikast|RÃƒÂ¥dhusstrÃƒÂ¦det|               12|       7430| 56.139|  9.154|     DKK|      VISA|              4166|Withdrawal|        null|        null|     56.139|      9.158|        2619426|            Ikast|281.15|    1011|     100|         6|     240|    0.0|        75|       300|     Drizzle|light intensity d...|\n",
      "|2017|January|  1| Sunday|   0|    Active|     4|             NCR|  Svogerslev|       BrÃƒÂ¸nsager|                1|       4000| 55.634| 12.018|     DKK|MasterCard|              5153|Withdrawal|        null|        null|     55.642|      12.08|        2614481|         Roskilde|280.61|    1014|      87|         7|     260|    0.0|        88|       701|        Mist|                mist|\n",
      "+----+-------+---+-------+----+----------+------+----------------+------------+-------------------+-----------------+-----------+-------+-------+--------+----------+------------------+----------+------------+------------+-----------+-----------+---------------+-----------------+------+--------+--------+----------+--------+-------+----------+----------+------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Showing Top 5 rows \n",
    "df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CREATING DIMENTION TABLES"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DIM_LOCATION DIMENTION TABLE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------+-------------+-------+------+-----+\n",
      "|            location|    streetname|street_number|zipcode|   lat|  lon|\n",
      "+--------------------+--------------+-------------+-------+------+-----+\n",
      "|NykÃƒÂ¸bing Mors ...|   Kirketorvet|            1|   7900|56.795| 8.86|\n",
      "|                Nibe|        Torvet|            1|   9240|56.983|9.639|\n",
      "|           Skipperen|   Vestre Alle|            2|   9000|57.034|9.908|\n",
      "|              Viborg|     Toldboden|            3|   8800|56.448|9.401|\n",
      "|               Vadum|Ellehammersvej|           43|   9430|57.118|9.861|\n",
      "+--------------------+--------------+-------------+-------+------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# dataframe for DIM_LOCATION dimention table\n",
    "# Selected only the colums required for DIM_LOCATION table\n",
    "\n",
    "DIM_LOCATION = df.select(col(\"atm_location\").alias(\"location\"),\n",
    "                            col(\"atm_streetname\").alias(\"streetname\"),\n",
    "                            col(\"atm_street_number\").alias(\"street_number\"), \n",
    "                            col(\"atm_zipcode\").alias(\"zipcode\"),\n",
    "                            col(\"atm_lat\").alias(\"lat\"), \n",
    "                            col(\"atm_lon\").alias(\"lon\"))\n",
    "\n",
    "\n",
    "#-----Check-------\n",
    "#DIM_LOCATION.show(5)\n",
    "\n",
    "\n",
    "# Cleaning \n",
    "# removing duplicates\n",
    "DIM_LOCATION = DIM_LOCATION.dropDuplicates()\n",
    "\n",
    "\n",
    "#show unique dataframe. --check\n",
    "DIM_LOCATION.show(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# auto increasing  number \n",
    "id_num = Window.orderBy(monotonically_increasing_id())\n",
    "\n",
    "\n",
    "#adding a column to the table DIM_LOCATION\n",
    "DIM_LOCATION = DIM_LOCATION.withColumn(\"location_id\", row_number().over(id_num))\n",
    "\n",
    "\n",
    "#appending serialnumber with string 'location_id' to form a primary key \n",
    "def location_Id(value):\n",
    "    return \"location_\" + str(value)\n",
    "location_id_sNo = udf(location_Id, StringType())\n",
    "\n",
    "\n",
    "# Creating a column (Primary Key) location_id \n",
    "#Updating the values in location_id col.\n",
    "DIM_LOCATION = DIM_LOCATION.withColumn(\"location_id\", location_id_sNo(\"location_id\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+--------------------+--------------+-------------+-------+------+-----+\n",
      "|location_id|            location|    streetname|street_number|zipcode|   lat|  lon|\n",
      "+-----------+--------------------+--------------+-------------+-------+------+-----+\n",
      "| location_1|NykÃƒÂ¸bing Mors ...|   Kirketorvet|            1|   7900|56.795| 8.86|\n",
      "| location_2|                Nibe|        Torvet|            1|   9240|56.983|9.639|\n",
      "| location_3|           Skipperen|   Vestre Alle|            2|   9000|57.034|9.908|\n",
      "| location_4|              Viborg|     Toldboden|            3|   8800|56.448|9.401|\n",
      "| location_5|               Vadum|Ellehammersvej|           43|   9430|57.118|9.861|\n",
      "+-----------+--------------------+--------------+-------------+-------+------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "109"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Rearranging columns according to the dimention table schema\n",
    "DIM_LOCATION = DIM_LOCATION.select('location_id','location','streetname','street_number','zipcode','lat','lon')\n",
    "\n",
    "#Showing final dimention table 'DIM_LOCATION' data \n",
    "DIM_LOCATION.show(5)\n",
    "\n",
    "#Verifying count of records in the table - 109\n",
    "DIM_LOCATION.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DIM_ATM dimention table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----------------+------+------+\n",
      "|atm_number|atm_manufacturer|lat   |lon   |\n",
      "+----------+----------------+------+------+\n",
      "|113       |Diebold Nixdorf |55.398|11.342|\n",
      "|54        |NCR             |56.745|8.949 |\n",
      "|104       |NCR             |57.049|9.922 |\n",
      "|18        |Diebold Nixdorf |56.448|9.401 |\n",
      "|8         |NCR             |56.762|8.867 |\n",
      "+----------+----------------+------+------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Creating DIM_ATM table with required cols as mentioned in the schema\n",
    "DIM_ATM = df.select(col(\"atm_id\").alias(\"atm_number\"), \n",
    "                    col(\"atm_manufacturer\"),\n",
    "                    col('atm_lat').alias('lat'),\n",
    "                    col('atm_lon').alias('lon'))\n",
    "\n",
    "\n",
    "# Cleaning \n",
    "# Removing duplicates\n",
    "DIM_ATM = DIM_ATM.dropDuplicates()\n",
    "\n",
    "\n",
    "# Showing top 5 rows\n",
    "DIM_ATM.show(5 , truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Joining the table with Location Table to get the required location_id.\n",
    "condition = [DIM_ATM.lat == DIM_LOCATION.lat, \n",
    "             DIM_ATM.lon == DIM_LOCATION.lon]\n",
    "\n",
    "DIM_ATM = DIM_ATM.join(DIM_LOCATION, condition, 'left_outer')\n",
    "\n",
    "\n",
    "# Assigning a unique value (primary key) to the atm_id column \n",
    "window = Window.orderBy(monotonically_increasing_id())\n",
    "DIM_ATM = DIM_ATM.withColumn(\"atm_id\", row_number().over(window))\n",
    "\n",
    "def atm_Id(value):\n",
    "    return \"atm_\" + str(value)\n",
    "atm_id_udf = udf(atm_Id, StringType())\n",
    "\n",
    "\n",
    "# Creating a column (Primary Key) atm_id\n",
    "#Updating the values in atm_id col.\n",
    "DIM_ATM = DIM_ATM.withColumn(\"atm_id\", atm_id_udf(\"atm_id\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+----------+----------------+---------------+\n",
      "|atm_id|atm_number|atm_manufacturer|atm_location_id|\n",
      "+------+----------+----------------+---------------+\n",
      "|atm_1 |113       |Diebold Nixdorf |location_104   |\n",
      "|atm_2 |113       |Diebold Nixdorf |location_90    |\n",
      "|atm_3 |54        |NCR             |location_93    |\n",
      "|atm_4 |104       |NCR             |location_63    |\n",
      "|atm_5 |104       |NCR             |location_25    |\n",
      "+------+----------+----------------+---------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "156"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Rearranging columns according to the dimention table schema\n",
    "DIM_ATM = DIM_ATM.select('atm_id',\n",
    "                         'atm_number',\n",
    "                         'atm_manufacturer',\n",
    "                         col('location_id').alias('atm_location_id'))\n",
    "\n",
    "\n",
    "#Showing final dimention table 'DIM_ATM' data \n",
    "DIM_ATM.show(5, truncate=False)\n",
    "\n",
    "\n",
    "# Verifing the total count for the dim_atm dimension.  156\n",
    "DIM_ATM.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DIM_DATE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Selecting required columns from the dataframe to create DIM_DATE dimention table\n",
    "DIM_DATE = df.select(col(\"year\"), \n",
    "                     \"month\", \n",
    "                     \"day\", \n",
    "                     \"hour\", \n",
    "                     \"weekday\")\n",
    "\n",
    "# Dropping duplicates from the DIM_DATE dataframe\n",
    "DIM_DATE = DIM_DATE.dropDuplicates()\n",
    "\n",
    "\n",
    "#DIM_DATE.show(5, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the date from year, month, and day column\n",
    "DIM_DATE = DIM_DATE.withColumn('month_int', from_unixtime(\n",
    "    unix_timestamp(col(\"month\"),'MMM'),'MM')).withColumn(\n",
    "    'date',date_format(concat_ws(\"-\",col('year'),col('month_int'),col('day')),\"yyyy-MM-dd\").cast('date'))\n",
    "\n",
    "# Creating the required timestamp column after merging the date\n",
    "DIM_DATE = DIM_DATE.withColumn('date',expr(\"date || '-' || hour || ':00:00'\")\n",
    "                   ).withColumn('date',to_timestamp('date','yyyy-MM-dd-HH:mm:ss'))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assigning a unique value (primary key) to the atm_id column \n",
    "window = Window.orderBy(monotonically_increasing_id())\n",
    "\n",
    "\n",
    "DIM_DATE = DIM_DATE.withColumn(\"date_id\", row_number().over(window))\n",
    "\n",
    "\n",
    "def date_Id(value):\n",
    "    return \"date_\" + str(value)\n",
    "date_udf = udf(date_Id, StringType())\n",
    "\n",
    "\n",
    "# Creating a column (Primary Key) date_id\n",
    "#Updating the values in date_id col.\n",
    "DIM_DATE = DIM_DATE.withColumn(\"date_id\", date_udf(\"date_id\"))\n",
    "\n",
    "#DIM_DATE.show(5,truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------------------+----+-------+---+----+--------+\n",
      "|date_id|full_date_time     |year|month  |day|hour|weekday |\n",
      "+-------+-------------------+----+-------+---+----+--------+\n",
      "|date_1 |2017-01-01 09:00:00|2017|January|1  |9   |Sunday  |\n",
      "|date_2 |2017-01-03 05:00:00|2017|January|3  |5   |Tuesday |\n",
      "|date_3 |2017-01-08 19:00:00|2017|January|8  |19  |Sunday  |\n",
      "|date_4 |2017-01-21 03:00:00|2017|January|21 |3   |Saturday|\n",
      "|date_5 |2017-01-23 21:00:00|2017|January|23 |21  |Monday  |\n",
      "+-------+-------------------+----+-------+---+----+--------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "8685"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Rearranging columns according to the dimention table schema\n",
    "DIM_DATE = DIM_DATE.select(col('date_id'),\n",
    "                           col('date').alias('full_date_time'),\n",
    "                           col(\"year\"), \n",
    "                           \"month\", \"day\", \"hour\", \"weekday\")\n",
    "\n",
    "DIM_DATE.show(5,truncate=False)\n",
    "\n",
    "# Verifing the total count for the DIM_DATE dimension.   -8685\n",
    "DIM_DATE.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DIM_CARD_TYPE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selecting required columns from the dataframe to create DIM_CARD_TYPE dimention table\n",
    "DIM_CARD_TYPE = df.select(col(\"card_type\"))\n",
    "\n",
    "# Dropping duplicates from the dim_card_type dataframe\n",
    "DIM_CARD_TYPE = DIM_CARD_TYPE.dropDuplicates()\n",
    "#DIM_CARD_TYPE.show(5, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assigning a unique value (primary key) to the atm_id column \n",
    "\n",
    "window = Window.orderBy(monotonically_increasing_id())\n",
    "\n",
    "\n",
    "DIM_CARD_TYPE = DIM_CARD_TYPE.withColumn(\"card_type_id\", row_number().over(window))\n",
    "def card_type_Id(value):\n",
    "    return \"card_type_\" + str(value)\n",
    "card_type_udf = udf(card_type_Id, StringType())\n",
    "\n",
    "\n",
    "\n",
    "# Creating a column (Primary Key) card_type_id\n",
    "#Updating the values in card_type_id col.\n",
    "DIM_CARD_TYPE = DIM_CARD_TYPE.withColumn(\"card_type_id\", card_type_udf(\"card_type_id\"))\n",
    "\n",
    "\n",
    "#DIM_CARD_TYPE.show(5, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+------------------+\n",
      "|card_type_id|card_type         |\n",
      "+------------+------------------+\n",
      "|card_type_1 |Dankort - on-us   |\n",
      "|card_type_2 |CIRRUS            |\n",
      "|card_type_3 |HÃƒÂ¦vekort       |\n",
      "|card_type_4 |VISA              |\n",
      "|card_type_5 |Mastercard - on-us|\n",
      "+------------+------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Rearranging columns according to the dimention table schema\n",
    "DIM_CARD_TYPE = DIM_CARD_TYPE.select('card_type_id','card_type')\n",
    "\n",
    "# showing top 5 rows of new dimention table DIM_CARD_TYPE\n",
    "DIM_CARD_TYPE.show(5, truncate=False)\n",
    "\n",
    "# Verifing the total count for the dim_atm dimension. 12\n",
    "DIM_CARD_TYPE.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CREATING FACT TABLE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Copying the full data into another dataframe to create the fact table\n",
    "FACT_ATM_TRANS = df.select('*')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Joining the table with DIM_LOCATION table to get the required location_id.\n",
    "condition = [FACT_ATM_TRANS.atm_location == DIM_LOCATION.location, \n",
    "             FACT_ATM_TRANS.atm_lat == DIM_LOCATION.lat,\n",
    "             FACT_ATM_TRANS.atm_lon == DIM_LOCATION.lon, \n",
    "             FACT_ATM_TRANS.atm_streetname == DIM_LOCATION.streetname, \n",
    "             FACT_ATM_TRANS.atm_street_number == DIM_LOCATION.street_number, \n",
    "             FACT_ATM_TRANS.atm_zipcode == DIM_LOCATION.zipcode]\n",
    "\n",
    "FACT_ATM_TRANS = FACT_ATM_TRANS.join(DIM_LOCATION, condition, 'left_outer').select('*')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Joining the table with DIM_CARD_TYPE table to get the required card_type_id.\n",
    "condition = [FACT_ATM_TRANS.card_type == DIM_CARD_TYPE.card_type]\n",
    "\n",
    "\n",
    "FACT_ATM_TRANS = FACT_ATM_TRANS.join(DIM_CARD_TYPE, condition, 'left_outer').select('*')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Joining the table with DIM_DATE table to get the required date_id.\n",
    "condition = [FACT_ATM_TRANS.year == DIM_DATE.year, \n",
    "             FACT_ATM_TRANS.month == DIM_DATE.month,\n",
    "             FACT_ATM_TRANS.day == DIM_DATE.day, \n",
    "             FACT_ATM_TRANS.hour == DIM_DATE.hour,\n",
    "            FACT_ATM_TRANS.weekday == DIM_DATE.weekday]\n",
    "\n",
    "\n",
    "FACT_ATM_TRANS = FACT_ATM_TRANS.join(DIM_DATE, condition, 'left_outer').select('*')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Joining the table with DIM_ATM table to get the required atm_id.\n",
    "FACT_ATM_TRANS = FACT_ATM_TRANS.withColumnRenamed(\"atm_id\",\"atm_id_fact\")\n",
    "\n",
    "\n",
    "condition = [FACT_ATM_TRANS.atm_id_fact == DIM_ATM.atm_number, \n",
    "             FACT_ATM_TRANS.atm_manufacturer == DIM_ATM.atm_manufacturer,\n",
    "             FACT_ATM_TRANS.location_id == DIM_ATM.atm_location_id]\n",
    "\n",
    "\n",
    "FACT_ATM_TRANS = FACT_ATM_TRANS.join(DIM_ATM, condition, 'left_outer').select('*')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Keeping only the rows mentioned in the fact table schema\n",
    "removedCol = ['atm_location',\n",
    "              'atm_streetname',\n",
    "              'atm_street_number',\n",
    "              'atm_zipcode',\n",
    "                   'atm_lat',\n",
    "              'atm_lon',\n",
    "              'location',\n",
    "              'streetname','street_number',\n",
    "              'zipcode','lat','lon','card_type',\n",
    "                  'year','month','day','hour',\n",
    "              'weekday','full_date_time',\n",
    "              'atm_manufacturer','atm_number',\n",
    "              'atm_id_fact','atm_location_id']\n",
    "\n",
    "\n",
    "FACT_ATM_TRANS = FACT_ATM_TRANS.drop(*removedCol)\n",
    "\n",
    "\n",
    "#FACT_ATM_TRANS.show(2, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assigning a unique value (primary key) to the trans_id column \n",
    "window = Window.orderBy(monotonically_increasing_id())\n",
    "\n",
    "\n",
    "FACT_ATM_TRANS = FACT_ATM_TRANS.withColumn('trans_id', row_number().over(window))\n",
    "\n",
    "\n",
    "def fact_atm_trans_Id(value):\n",
    "    return \"trans_\" + str(value)\n",
    "fact_atm_trans_udf = udf(fact_atm_trans_Id, StringType())\n",
    "\n",
    "\n",
    "FACT_ATM_TRANS = FACT_ATM_TRANS.withColumn('trans_id', fact_atm_trans_udf('trans_id'))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rearranging columns according to the fact table schema\n",
    "\n",
    "FACT_ATM_TRANS = FACT_ATM_TRANS.select('trans_id',\n",
    "                                       'atm_id',\n",
    "                                       col('location_id').alias('weather_location_id'),\n",
    "                                       'date_id',\n",
    "                                       'card_type_id',\n",
    "                                       'atm_status',\n",
    "                                       'currency',\n",
    "                                       'service',\n",
    "                                       'transaction_amount',\n",
    "                                       'message_code',\n",
    "                                      'message_text',\n",
    "                                       'rain_3h',\n",
    "                                       'clouds_all',\n",
    "                                       'weather_id',\n",
    "                                       'weather_main',\n",
    "                                       'weather_description')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+------+-------------------+---------+------------+----------+--------+----------+------------------+------------+------------+-------+----------+----------+------------+-------------------+\n",
      "|trans_id|atm_id|weather_location_id|date_id  |card_type_id|atm_status|currency|service   |transaction_amount|message_code|message_text|rain_3h|clouds_all|weather_id|weather_main|weather_description|\n",
      "+--------+------+-------------------+---------+------------+----------+--------+----------+------------------+------------+------------+-------+----------+----------+------------+-------------------+\n",
      "|trans_1 |atm_40|location_101       |date_4715|card_type_2 |Inactive  |DKK     |Withdrawal|5399              |null        |null        |0.0    |0         |800       |Clear       |Sky is Clear       |\n",
      "|trans_2 |atm_40|location_101       |date_183 |card_type_4 |Inactive  |DKK     |Withdrawal|3774              |null        |null        |0.0    |92        |804       |Clouds      |overcast clouds    |\n",
      "+--------+------+-------------------+---------+------------+----------+--------+----------+------------------+------------+------------+-------+----------+----------+------------+-------------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2468572"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# showing top 2 rows of the final fact table FACT_ATM_TRANS\n",
    "FACT_ATM_TRANS.show(2, truncate=False)\n",
    "\n",
    "# Verifying the count of the fact table:  2468572\n",
    "FACT_ATM_TRANS.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WRITING DATA INTO S3 BUCKET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Writing data to the s3 bucket using write method for DIM_LOCATION table\n",
    "DIM_LOCATION.write.csv(\"s3a://etlproj/Dim_Location/Dim_Location.csv\", mode=\"overwrite\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Writing data to the s3 bucket using write method for DIM_CARD_TYPE table\n",
    "DIM_CARD_TYPE.write.csv(\"s3a://etlproj/Dim_Card_Type/Dim_Card_Type.csv\", mode=\"overwrite\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Writing data to the s3 bucket using write method for DIM_ATM table\n",
    "DIM_ATM.write.csv(\"s3a://etlproj/Dim_ATM/Dim_ATM.csv\", mode=\"overwrite\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Writing data to the s3 bucket using write method for DIM_DATE table\n",
    "DIM_DATE.write.parquet(\"s3a://etlproj/Dim_Date/Dim_Date.parquet\", mode=\"overwrite\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Writing data to the s3 bucket using write method for FACT_ATM_TRANS table\n",
    "FACT_ATM_TRANS.write.csv(\"s3a://etlproj/Fact_Transaction/Fact_Transaction.csv\", mode=\"overwrite\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
